# -*- coding: utf-8 -*-
"""AQED_CIFAR10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X6YHYFPL3J2b4yLMHDXMP0JHAVbvD0tI

# CIFAR-10
## CNN Feature Extraction + Quantum Enhancement


---

### Why Previous Approach Failed:
- PCA loses too much spatial information from images
- CIFAR-10 images have complex patterns that PCA can't capture

### CNN Features + Quantum
- Use **pre-trained CNN** (ResNet/VGG) to extract meaningful features
- Apply **quantum enhancement** to CNN features
- This is valid for thesis: "Quantum enhancement of deep learning features"
"""

!pip install qiskit qiskit-machine-learning scikit-learn numpy requests matplotlib seaborn pylatexenc --quiet

import numpy as np
import json
import time
import requests
import warnings
warnings.filterwarnings('ignore')

from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from qiskit import QuantumCircuit
from qiskit.quantum_info import Statevector
from qiskit_machine_learning.kernels import FidelityQuantumKernel
from qiskit.circuit.library import ZZFeatureMap, ZFeatureMap

import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.models import Model

import matplotlib.pyplot as plt
import seaborn as sns

print("All imports successful!")

# SET YOUR CLAUDE API KEY
CLAUDE_API_KEY = ""  # Replace with your actual API key

if CLAUDE_API_KEY == "your-api-key-here":
    print("Please set your Claude API key!")
else:
    print("API key set!")

"""---
## Part 1: AQED Circuit Designer
"""

class AQEDCircuitDesigner:
    """AQED: Claude API designs quantum circuits."""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.api_url = "https://api.anthropic.com/v1/messages"
        self.model = "claude-sonnet-4-20250514"

    def design_circuit(self, n_qubits: int, n_features: int) -> dict:
        prompt = f"""Design quantum circuit for CIFAR-10 classification with CNN features.
Qubits: {n_qubits}, Features: {n_features}
Return ONLY JSON: {{"encoding": "angle", "entanglement": "circular", "layers": 2, "gates": ["RY", "RZ"]}}"""

        try:
            print("AQED: Calling Claude API...")
            start = time.time()
            response = requests.post(self.api_url,
                headers={"Content-Type": "application/json", "x-api-key": self.api_key, "anthropic-version": "2023-06-01"},
                json={"model": self.model, "max_tokens": 200, "messages": [{"role": "user", "content": prompt}]},
                timeout=60)
            api_time = time.time() - start

            content = response.json()['content'][0]['text'].strip()
            if "{" in content:
                content = content[content.find("{"):content.rfind("}")+1]
            config = json.loads(content)
            config['api_time'] = api_time

            print(f" Circuit designed in {api_time:.2f}s")
            return config
        except Exception as e:
            print(f"Using default config")
            return {"encoding": "angle", "entanglement": "circular", "layers": 2, "gates": ["RY", "RZ"]}

print(" AQEDCircuitDesigner ready!")

"""---
## Part 2: CNN Feature Extractor (VGG16)
"""

class CNNFeatureExtractor:
    """
    Extract deep features using pre-trained VGG16.
    These features are MUCH better than PCA for image classification.
    """

    def __init__(self):
        print("\nðŸ“¦ Loading VGG16 (pre-trained on ImageNet)...")

        # Load VGG16 without top classification layer
        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))

        # Use output of last conv block as features
        self.model = Model(inputs=base_model.input, outputs=base_model.output)

        print("VGG16 loaded!")
        print(f"   Output shape: {self.model.output_shape}")

    def extract(self, X: np.ndarray, batch_size: int = 64) -> np.ndarray:
        """
        Extract CNN features from images.

        Args:
            X: Images of shape (n_samples, 32, 32, 3), values in [0, 255]

        Returns:
            Features of shape (n_samples, n_features)
        """
        print(f"\nExtracting CNN features from {len(X)} images...")

        # Preprocess for VGG16
        X_prep = preprocess_input(X.astype(np.float32))

        # Extract features
        features = self.model.predict(X_prep, batch_size=batch_size, verbose=1)

        # Flatten
        features = features.reshape(len(X), -1)

        print(f"CNN features extracted: {features.shape}")
        return features

print("CNNFeatureExtractor ready!")

"""---
## Part 3: Quantum Feature Enhancer
"""

class QuantumFeatureEnhancer:
    """
    Enhance classical features using quantum circuits.
    Takes PCA-reduced CNN features and adds quantum-derived features.
    """

    def __init__(self, n_qubits: int = 6, n_layers: int = 5):
        self.n_qubits = n_qubits
        self.n_layers = n_layers
        self.n_quantum_features = 2 ** n_qubits

        print(f"\nQuantum Feature Enhancer:")
        print(f"   Qubits: {n_qubits}")
        print(f"   Layers: {n_layers}")
        print(f"   Quantum features: {self.n_quantum_features}")

    def build_circuit(self, features: np.ndarray) -> QuantumCircuit:
        qc = QuantumCircuit(self.n_qubits)
        n_f = len(features)

        for layer in range(self.n_layers):
            for i in range(self.n_qubits):
                f_idx = (layer * self.n_qubits + i) % n_f
                qc.ry(features[f_idx] * np.pi, i)
                qc.rz(features[(f_idx + 1) % n_f] * np.pi, i)

            for i in range(self.n_qubits):
                qc.cx(i, (i + 1) % self.n_qubits)

        return qc

    def enhance(self, X: np.ndarray, verbose: bool = True) -> np.ndarray:
        """Add quantum features to input features."""
        n_samples = len(X)

        if verbose:
            print(f"\n Generating quantum features for {n_samples} samples...")

        quantum_features = np.zeros((n_samples, self.n_quantum_features))
        start = time.time()

        for i, x in enumerate(X):
            qc = self.build_circuit(x)
            sv = Statevector.from_instruction(qc)
            quantum_features[i] = np.abs(sv.data) ** 2

            if verbose and (i + 1) % 1000 == 0:
                elapsed = time.time() - start
                print(f"   Processed {i+1}/{n_samples} ({(i+1)/elapsed:.1f}/s)")

        if verbose:
            print(f" Done in {time.time()-start:.1f}s")

        # Combine original + quantum features
        enhanced = np.hstack([X, quantum_features])
        if verbose:
            print(f"   Enhanced features: {enhanced.shape}")

        return enhanced

print(" QuantumFeatureEnhancer ready!")

"""---
## Part 4: Load and Prepare CIFAR-10
"""

def load_cifar10_with_cnn_features(n_pca: int = 32, n_total: int = 10000, seed: int = 42):
    """
    Load CIFAR-10 and extract CNN features.
    """
    print("\n" + "="*60)
    print("LOADING CIFAR-10 WITH CNN FEATURES")
    print("="*60)

    # Load CIFAR-10
    print("\nðŸ“¥ Loading CIFAR-10...")
    (X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = cifar10.load_data()

    X_all = np.vstack([X_train_raw, X_test_raw])
    y_all = np.hstack([y_train_raw.flatten(), y_test_raw.flatten()])

    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

    # Stratified sampling
    print(f"\nðŸ“Š Stratified sampling {n_total} samples...")
    rng = np.random.RandomState(seed)
    n_per_class = n_total // 10

    indices = []
    for c in range(10):
        c_idx = np.where(y_all == c)[0]
        selected = rng.choice(c_idx, n_per_class, replace=False)
        indices.extend(selected)

    indices = np.array(indices)
    rng.shuffle(indices)

    X = X_all[indices]
    y = y_all[indices]

    # Extract CNN features
    cnn_extractor = CNNFeatureExtractor()
    X_cnn = cnn_extractor.extract(X)

    # PCA reduction of CNN features
    print(f"\nðŸ“‰ PCA: {X_cnn.shape[1]} â†’ {n_pca} dimensions")
    pca = PCA(n_components=n_pca, random_state=seed)
    X_pca = pca.fit_transform(X_cnn)
    variance = sum(pca.explained_variance_ratio_)
    print(f"   Variance explained: {variance:.3f}")

    # Scale to [0, 1]
    scaler = MinMaxScaler(feature_range=(0, 1))
    X_scaled = scaler.fit_transform(X_pca)

    # Split: 6000 / 2000 / 2000
    print(f"\nâœ‚ï¸ Split: 6000 train / 2000 val / 2000 test")

    X_train = X_scaled[:6000]
    y_train = y[:6000]
    X_val = X_scaled[6000:8000]
    y_val = y[6000:8000]
    X_test = X_scaled[8000:10000]
    y_test = y[8000:10000]

    print(f"\n Data ready:")
    print(f"   Train: {X_train.shape}")
    print(f"   Test: {X_test.shape}")

    return {
        'X_train': X_train, 'y_train': y_train,
        'X_val': X_val, 'y_val': y_val,
        'X_test': X_test, 'y_test': y_test,
        'class_names': class_names,
        'pca_variance': variance
    }

print("Data loader ready!")

"""---
## Part 5: Run Experiment
"""

# Configuration
N_PCA = 80          # PCA components from CNN features
N_QUBITS = 10        # Qubits for quantum enhancement
N_LAYERS = 5        # Quantum circuit layers

print(f"Configuration:")
print(f"   CNN features â†’ PCA: {N_PCA}")
print(f"   Quantum features: {2**N_QUBITS}")
print(f"   Total features: {N_PCA + 2**N_QUBITS}")

# Load data with CNN features
data = load_cifar10_with_cnn_features(n_pca=N_PCA)

# Prepare data
X_train = data['X_train']
y_train = data['y_train']
X_test = data['X_test']
y_test = data['y_test']

print(f"Data shapes:")
print(f"   Train: {X_train.shape}")
print(f"   Test: {X_test.shape}")

# AQED: Claude designs circuit

designer = AQEDCircuitDesigner(CLAUDE_API_KEY)
config = designer.design_circuit(N_QUBITS, N_PCA)

# Create quantum enhancer
enhancer = QuantumFeatureEnhancer(n_qubits=N_QUBITS, n_layers=N_LAYERS)

# Enhance training features
X_train_enhanced = enhancer.enhance(X_train)

# Enhance test features
X_test_enhanced = enhancer.enhance(X_test)

# Train classifier
# Scale enhanced features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_enhanced)
X_test_scaled = scaler.transform(X_test_enhanced)

# Train SVM
print("Training SVM on quantum-enhanced features...")
svm = SVC(kernel='rbf', C=10.0, gamma='scale')
svm.fit(X_train_scaled, y_train)

train_acc = svm.score(X_train_scaled, y_train)
print(f"Training accuracy: {train_acc*100:.2f}%")

# Evaluate
y_pred = svm.predict(X_test_scaled)
hybrid_acc = accuracy_score(y_test, y_pred)

if hybrid_acc >= 0.50:
    print(f"AQED-HYBRID ACCURACY: {hybrid_acc*100:.2f}%")
    print(f"   TARGET ACHIEVED! (â‰¥50%)")
else:
    print(f"AQED-HYBRID ACCURACY: {hybrid_acc*100:.2f}%")
print(f"   Random Chance: 10%")
print(f"   Improvement: {(hybrid_acc - 0.10)*100:.2f}%")

# Classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=data['class_names'], digits=4))

# Classical baselines (CNN features only, no quantum)
baselines = {}

# Scale original features (no quantum)
scaler_orig = StandardScaler()
X_train_orig = scaler_orig.fit_transform(X_train)
X_test_orig = scaler_orig.transform(X_test)

print("SVM (CNN features only)...")
svm_orig = SVC(kernel='rbf', C=10.0, gamma='scale')
svm_orig.fit(X_train_orig, y_train)
baselines['SVM (CNN only)'] = svm_orig.score(X_test_orig, y_test)
print(f"Accuracy: {baselines['SVM (CNN only)']*100:.2f}%")

print("Random Forest (CNN features only)...")
rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
rf.fit(X_train_orig, y_train)
baselines['RF (CNN only)'] = rf.score(X_test_orig, y_test)
print(f"Accuracy: {baselines['RF (CNN only)']*100:.2f}%")

# Results comparison
all_results = {**baselines, 'AQED-Hybrid (CNN+Quantum)': hybrid_acc}

print(f"{'Method':<30} {'Accuracy':>12} {'vs Random':>12}")
for method, acc in sorted(all_results.items(), key=lambda x: x[1], reverse=True):
    marker = " done "if "Quantum" in method else " not yet "
    check = "yes" if acc >= 0.50 else "no"
    print(f"{marker} {method:<28} {acc*100:>11.2f}% {(acc-0.1)*100:>+11.2f}% {check}")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support
from sklearn.decomposition import PCA

# Publication style
plt.rcParams.update({
    'font.family': 'serif',
    'font.size': 11,
    'axes.labelsize': 12,
    'axes.titlesize': 13,
    'figure.dpi': 150,
    'savefig.dpi': 300,
})

# Get metrics
cm = confusion_matrix(y_test, y_pred)
precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred)
class_names = data['class_names']

# Get baseline accuracies
svm_cnn_acc = baselines['SVM (CNN only)']
rf_cnn_acc = baselines['RF (CNN only)']


# GRAPH 1: FEATURE ENHANCEMENT VISUALIZATION + QUANTUM KERNEL
fig1, axes = plt.subplots(1, 2, figsize=(12, 4.5))

# Left: Feature dimension comparison
categories = ['CNN+PCA\nFeatures', 'Quantum\nFeatures', 'Hybrid\n(Combined)']
dimensions = [N_PCA, 2**N_QUBITS, N_PCA + 2**N_QUBITS]
colors = ['#3498db', '#9b59b6', '#d62728']

bars = axes[0].bar(categories, dimensions, color=colors, edgecolor='black', linewidth=1)
axes[0].set_ylabel('Number of Features')
axes[0].set_title('CIFAR-10: Feature Space Dimensionality')
axes[0].set_yscale('log')
for bar, dim in zip(bars, dimensions):
    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.1,
                 f'{dim}', ha='center', fontsize=11, fontweight='bold')

# Right: Quantum Kernel Matrix
n_sample = min(50, len(X_test))
np.random.seed(42)
sample_idx = np.random.choice(len(X_test), n_sample, replace=False)

print("  Computing quantum kernel matrix...")
# Use enhanced features (quantum part only)
Q_sample = X_test_enhanced[sample_idx, N_PCA:]  # Quantum features only

# Compute kernel
K = Q_sample @ Q_sample.T

# Sort by class
sort_idx = np.argsort(y_test[sample_idx])
K_sorted = K[sort_idx][:, sort_idx]

im = axes[1].imshow(K_sorted, cmap='bwr', aspect='auto')
axes[1].set_xlabel('Sample Index (sorted by class)')
axes[1].set_ylabel('Sample Index (sorted by class)')
axes[1].set_title('CIFAR-10: Quantum Feature Kernel Matrix')
plt.colorbar(im, ax=axes[1], shrink=0.8)

plt.tight_layout()
plt.savefig('graph1_cifar10_features_kernel.png', dpi=300, bbox_inches='tight')
plt.savefig('graph1_cifar10_features_kernel.pdf', bbox_inches='tight')
plt.show()


# GRAPH 2: CLASSIFICATION SCATTER WITH MISCLASSIFICATIONS
fig2, ax = plt.subplots(figsize=(10, 8))

# Reduce enhanced features to 2D
pca_2d = PCA(n_components=2)
X_test_2d = pca_2d.fit_transform(X_test_enhanced)

# Plot each class
colors_scatter = plt.cm.tab10(np.linspace(0, 1, 10))
for cls in range(10):
    mask = y_test == cls
    ax.scatter(X_test_2d[mask, 0], X_test_2d[mask, 1],
               c=[colors_scatter[cls]], label=class_names[cls],
               alpha=0.6, s=25, edgecolors='none')

# Highlight misclassified
misclassified = y_test != y_pred
ax.scatter(X_test_2d[misclassified, 0], X_test_2d[misclassified, 1],
           facecolors='none', edgecolors='red', s=100, linewidths=1.5,
           label=f'Misclassified ({misclassified.sum()})')

ax.set_xlabel('Principal Component #0')
ax.set_ylabel('Principal Component #1')
ax.set_title(f'CIFAR-10: Classification Results (Accuracy: {hybrid_acc*100:.1f}%)\nRed circles = misclassified samples')
ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('graph2_cifar10_classification_scatter.png', dpi=300, bbox_inches='tight')
plt.savefig('graph2_cifar10_classification_scatter.pdf', bbox_inches='tight')
plt.show()

# GRAPH 3: CNN vs CNN+QUANTUM FEATURE PROJECTION
fig3, axes = plt.subplots(1, 2, figsize=(14, 5.5))

# Sample for visualization
n_sample = min(300, len(X_test))
np.random.seed(42)
sample_idx = np.random.choice(len(X_test), n_sample, replace=False)

# PCA on CNN-only features
pca_cnn = PCA(n_components=2)
X_cnn_2d = pca_cnn.fit_transform(X_test[sample_idx])

# PCA on quantum-enhanced features
pca_hybrid = PCA(n_components=2)
X_hybrid_2d = pca_hybrid.fit_transform(X_test_enhanced[sample_idx])

# LEFT: CNN-only projection
for cls in range(10):
    mask = y_test[sample_idx] == cls
    axes[0].scatter(X_cnn_2d[mask, 0], X_cnn_2d[mask, 1],
                   c=[plt.cm.tab10(cls/10)], marker='o', s=30, alpha=0.7,
                   edgecolors='white', linewidths=0.3,
                   label=class_names[cls] if cls < 5 else None)

axes[0].set_xlabel('Principal Component #0')
axes[0].set_ylabel('Principal Component #1')
axes[0].set_title('Projection using CNN Features Only')
axes[0].grid(True, alpha=0.3)
axes[0].legend(loc='upper right', fontsize=7)

# RIGHT: Quantum-enhanced projection
for cls in range(10):
    mask = y_test[sample_idx] == cls
    axes[1].scatter(X_hybrid_2d[mask, 0], X_hybrid_2d[mask, 1],
                   c=[plt.cm.tab10(cls/10)], marker='o', s=30, alpha=0.7,
                   edgecolors='white', linewidths=0.3,
                   label=class_names[cls] if cls >= 5 else None)

axes[1].set_xlabel('Principal Component #0')
axes[1].set_ylabel('Principal Component #1')
axes[1].set_title('Projection using CNN + Quantum Features')
axes[1].grid(True, alpha=0.3)
axes[1].legend(loc='upper right', fontsize=7)

plt.suptitle('CIFAR-10: CNN vs Quantum-Enhanced Feature Space', fontsize=14, fontweight='bold', y=1.02)
plt.tight_layout()
plt.savefig('graph3_cifar10_feature_projection.png', dpi=300, bbox_inches='tight')
plt.savefig('graph3_cifar10_feature_projection.pdf', bbox_inches='tight')
plt.show()

# GRAPH 4: COMPREHENSIVE 4-PANEL RESULTS SUMMARY
fig4 = plt.figure(figsize=(14, 11))

# (a) Model comparison
ax1 = fig4.add_subplot(2, 2, 1)
models = ['SVM\n(CNN only)', 'Random Forest\n(CNN only)', 'AQED-Hybrid\n(CNN+Quantum)']
accs = [svm_cnn_acc*100, rf_cnn_acc*100, hybrid_acc*100]
colors_bar = ['#7f7f7f', '#7f7f7f', '#d62728']
bars = ax1.bar(models, accs, color=colors_bar, edgecolor='black', linewidth=1)
ax1.axhline(y=50, color='green', linestyle='--', linewidth=2, label='50% Target')
ax1.axhline(y=10, color='orange', linestyle=':', linewidth=2, label='Random Chance (10%)')
ax1.set_ylabel('Test Accuracy (%)')
ax1.set_title('(a) Model Comparison', fontweight='bold')
ax1.set_ylim(0, max(accs)+10)
ax1.legend(loc='upper left', fontsize=9)
for bar, acc in zip(bars, accs):
    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
             f'{acc:.1f}%', ha='center', fontsize=11, fontweight='bold')
ax1.spines['top'].set_visible(False)
ax1.spines['right'].set_visible(False)

# (b) Confusion matrix with class names
ax2 = fig4.add_subplot(2, 2, 2)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', ax=ax2,
            xticklabels=[c[:5] for c in class_names],
            yticklabels=[c[:5] for c in class_names],
            cbar_kws={'shrink': 0.8}, annot_kws={'size': 7})
ax2.set_xlabel('Predicted Label')
ax2.set_ylabel('True Label')
ax2.set_title(f'(b) Normalized Confusion Matrix\n(Accuracy: {hybrid_acc*100:.1f}%)', fontweight='bold')
plt.setp(ax2.get_xticklabels(), rotation=45, ha='right', fontsize=8)
plt.setp(ax2.get_yticklabels(), rotation=0, fontsize=8)

# (c) Per-class F1 scores
ax3 = fig4.add_subplot(2, 2, 3)
x = np.arange(10)
colors_f1 = plt.cm.tab10(np.linspace(0, 1, 10))
bars_f1 = ax3.bar(x, f1, color=colors_f1, edgecolor='black', linewidth=0.5)
ax3.set_xlabel('Class')
ax3.set_ylabel('F1-Score')
ax3.set_title('(c) Per-Class F1 Scores', fontweight='bold')
ax3.set_xticks(x)
ax3.set_xticklabels([c[:5] for c in class_names], rotation=45, ha='right', fontsize=8)
ax3.axhline(y=0.5, color='green', linestyle='--', alpha=0.7, label='50% Target')
ax3.set_ylim(0, max(f1)+0.1)
ax3.legend(loc='upper right')
ax3.spines['top'].set_visible(False)
ax3.spines['right'].set_visible(False)

# (d) Improvement over random chance
ax4 = fig4.add_subplot(2, 2, 4)
methods = ['Random\nChance', 'SVM\n(CNN)', 'RF\n(CNN)', 'AQED-Hybrid\n(Ours)']
improvements = [0, (svm_cnn_acc-0.1)*100, (rf_cnn_acc-0.1)*100, (hybrid_acc-0.1)*100]
colors_imp = ['#bdc3c7', '#7f7f7f', '#7f7f7f', '#d62728']
bars_imp = ax4.bar(methods, improvements, color=colors_imp, edgecolor='black', linewidth=1)
ax4.set_ylabel('Improvement over Random (%)')
ax4.set_title('(d) Performance Gain Analysis', fontweight='bold')
ax4.axhline(y=40, color='green', linestyle='--', linewidth=1.5, label='40% improvement target')
for bar, imp in zip(bars_imp, improvements):
    if imp > 0:
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                 f'+{imp:.1f}%', ha='center', fontsize=10, fontweight='bold')
ax4.legend(loc='upper left')
ax4.spines['top'].set_visible(False)
ax4.spines['right'].set_visible(False)

plt.suptitle(f'AQED-Hybrid Results on CIFAR-10 (VGG16 + Quantum Enhancement)',
             fontsize=16, fontweight='bold', y=1.01)
plt.tight_layout()
plt.savefig('graph4_cifar10_comprehensive.png', dpi=300, bbox_inches='tight')
plt.savefig('graph4_cifar10_comprehensive.pdf', bbox_inches='tight')
plt.show()



# Per-class analysis
print(f"{'Class':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}")
for i, name in enumerate(class_names):
    print(f"{name:<12} {precision[i]:.4f}       {recall[i]:.4f}       {f1[i]:.4f}")

# Find patterns
easiest = class_names[np.argmax(f1)]
hardest = class_names[np.argmin(f1)]
print(f"\nEasiest class: {easiest} (F1: {np.max(f1):.4f})")
print(f"Hardest class: {hardest} (F1: {np.min(f1):.4f})")

# Confusion analysis
print("\n" + "="*60)
print("COMMON CONFUSIONS")
print("="*60)
cm_off_diag = cm.copy()
np.fill_diagonal(cm_off_diag, 0)
top_confusions = []
for i in range(10):
    for j in range(10):
        if i != j and cm_off_diag[i, j] > 0:
            top_confusions.append((cm_off_diag[i, j], class_names[i], class_names[j]))
top_confusions.sort(reverse=True)
print("Top 5 misclassification pairs:")
for count, true_cls, pred_cls in top_confusions[:5]:
    print(f"  {true_cls} â†’ {pred_cls}: {count} samples")